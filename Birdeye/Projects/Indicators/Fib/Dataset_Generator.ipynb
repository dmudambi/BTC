{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtesting Fibonacci Retracement Post Wave 1 Peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"success\":true,\"data\":[\"solana\",\"ethereum\",\"arbitrum\",\"avalanche\",\"bsc\",\"optimism\",\"polygon\",\"base\",\"zksync\"]}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Path to Master Functions and Keys\n",
    "current_dir = os.getcwd()\n",
    "root_dir = os.path.abspath(os.path.join(current_dir, '..', '..', '..', '..'))\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "import Birdeye.Basics.Master_Functions as Master_Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Tokens by Market Cap Range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Established Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsort_by = \"mc\"  # mc, v24hUSD, v24hChangePercent \\nsort_type = \"desc\"  # asc, desc\\nmin_liquidity = 100000  # Minimum liquidity in USD (100k)\\nmin_volume_24h = 1000000  # Minimum 24-hour trading volume in USD\\nmin_market_cap = 1000000  # Minimum market cap in USD (1 million)\\nmax_market_cap = 900000000  # Maximum market cap in USD (900 million)\\ntotal_tokens = 300  # Change this to the number of tokens you want to retrieve\\n\\n# Get the list of established tokens\\nestablished_tokens_filtered = Master_Functions.get_token_list(sort_by, sort_type, min_liquidity, min_volume_24h, min_market_cap, max_market_cap, total_tokens, chain, API_Key)\\n#print(established_tokens_filtered)\\n\\n# Set the index to \\'Address\\'\\nestablished_tokens_filtered = established_tokens_filtered.set_index(\\'Address\\')\\n\\n# Get the list of addresses\\nestablished_tokens_addresses = established_tokens_filtered.index.tolist()\\n\\n# Get Token Overview Data for established tokens\\nestablished_tokens_data = Master_Functions.get_token_trade_data_multi(established_tokens_addresses, API_Key)\\n\\n# Get a list of all unique attributes across all DataFrames\\nall_attributes = set()\\nfor token, df in established_tokens_data.items():\\n    if isinstance(df, pd.DataFrame) and not df.empty:\\n        all_attributes.update(df[\\'Attribute\\'].unique())\\n\\n# Convert the set to a sorted list\\ncolumns_array = sorted(list(all_attributes))\\n\\n# Create the master DataFrame\\nestablished_tokens_master_overview = pd.DataFrame(index=established_tokens_data.keys(), columns=columns_array)\\n\\n# Fill the DataFrame with values\\nfor token, df in established_tokens_data.items():\\n    if isinstance(df, pd.DataFrame) and not df.empty:\\n        for _, row in df.iterrows():\\n            established_tokens_master_overview.at[token, row[\\'Attribute\\']] = row[\\'Value\\']\\n\\n# Set the index name to \\'Address\\'\\nestablished_tokens_master_overview.index.name = \\'Address\\'\\n\\n# Optional: Save to CSV\\nestablished_tokens_master_overview.to_csv(\\'Data/established_tokens_master_overview.csv\\')\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "sort_by = \"mc\"  # mc, v24hUSD, v24hChangePercent \n",
    "sort_type = \"desc\"  # asc, desc\n",
    "min_liquidity = 100000  # Minimum liquidity in USD (100k)\n",
    "min_volume_24h = 1000000  # Minimum 24-hour trading volume in USD\n",
    "min_market_cap = 1000000  # Minimum market cap in USD (1 million)\n",
    "max_market_cap = 900000000  # Maximum market cap in USD (900 million)\n",
    "total_tokens = 300  # Change this to the number of tokens you want to retrieve\n",
    "\n",
    "# Get the list of established tokens\n",
    "established_tokens_filtered = Master_Functions.get_token_list(sort_by, sort_type, min_liquidity, min_volume_24h, min_market_cap, max_market_cap, total_tokens, chain, API_Key)\n",
    "#print(established_tokens_filtered)\n",
    "\n",
    "# Set the index to 'Address'\n",
    "established_tokens_filtered = established_tokens_filtered.set_index('Address')\n",
    "\n",
    "# Get the list of addresses\n",
    "established_tokens_addresses = established_tokens_filtered.index.tolist()\n",
    "\n",
    "# Get Token Overview Data for established tokens\n",
    "established_tokens_data = Master_Functions.get_token_trade_data_multi(established_tokens_addresses, API_Key)\n",
    "\n",
    "# Get a list of all unique attributes across all DataFrames\n",
    "all_attributes = set()\n",
    "for token, df in established_tokens_data.items():\n",
    "    if isinstance(df, pd.DataFrame) and not df.empty:\n",
    "        all_attributes.update(df['Attribute'].unique())\n",
    "\n",
    "# Convert the set to a sorted list\n",
    "columns_array = sorted(list(all_attributes))\n",
    "\n",
    "# Create the master DataFrame\n",
    "established_tokens_master_overview = pd.DataFrame(index=established_tokens_data.keys(), columns=columns_array)\n",
    "\n",
    "# Fill the DataFrame with values\n",
    "for token, df in established_tokens_data.items():\n",
    "    if isinstance(df, pd.DataFrame) and not df.empty:\n",
    "        for _, row in df.iterrows():\n",
    "            established_tokens_master_overview.at[token, row['Attribute']] = row['Value']\n",
    "\n",
    "# Set the index name to 'Address'\n",
    "established_tokens_master_overview.index.name = 'Address'\n",
    "\n",
    "# Optional: Save to CSV\n",
    "established_tokens_master_overview.to_csv('Data/established_tokens_master_overview.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Token Listings Summary + OHLCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------\n",
      "\n",
      "Running on: solana\n",
      "\n",
      "--------------------------------\n",
      "\n",
      "NEW TOKEN FILTERS:\n",
      "\n",
      "Min Liquidity: 30K\n",
      "Max Liquidity: 1.00Mil\n",
      "Min Market Cap: 450K\n",
      "Max Market Cap: 3.00Mil\n",
      "Filtering New Tokens for: 0 days, 2 hours, 0 minutes back\n",
      "Token Launch Liquidity Filter: 10K\n",
      "\n",
      "--------------------------------\n",
      " \n",
      " Collecting New Token Listings...\n",
      " \n",
      "--------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed with status code: 204\n",
      "https://dexscreener.com/solana/66d7tzRVVWMKTAnXnzr485QXJgCHECVxhuwEqFNAtXqe - Market Cap: 2.20Mil\n",
      "https://dexscreener.com/solana/DxQwEZvCdAPfvw8PiUSVjvATxowQJ5FJL8bBiHUbpump - Market Cap: 1.02Mil\n",
      "https://dexscreener.com/solana/9fEXUmPnDJYAXpoZ9nWi1gQZPwzVKdf8g9fYXW6Epump - Market Cap: 699K\n",
      "\n",
      "Token summary data saved to: Data/New_Token_Data/2024_11_05/Token_Summary/2024_Nov_05_1051PM/new_tokens_mc_added_filtered_0.5M-3.0M_0d_2h_0m.csv\n",
      "\n",
      "Number of Tokens Filtered: 3\n",
      "\n",
      "--------------------------------\n",
      " \n",
      "All Token summary data saved to: Data/New_Token_Data/2024_11_05/Token_Summary/2024_Nov_05_1051PM/new_tokens_mc_added_filtered_0.5M-3.0M_0d_2h_0m.csv\n",
      " \n",
      "--------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Prints ####   \n",
    "\n",
    "print(\"\\n--------------------------------\\n\")\n",
    "print(f\"Running on: {Master_Functions.chain}\")\n",
    "print(\"\\n--------------------------------\\n\")\n",
    "print(\"NEW TOKEN FILTERS:\")\n",
    "print(f\"\\nMin Liquidity: {Master_Functions.format_number(Master_Functions.new_token_min_liquidity)}\")\n",
    "print(f\"Max Liquidity: {Master_Functions.format_number(Master_Functions.new_token_max_liquidity)}\")\n",
    "print(f\"Min Market Cap: {Master_Functions.format_number(Master_Functions.new_token_min_market_cap)}\")\n",
    "print(f\"Max Market Cap: {Master_Functions.format_number(Master_Functions.new_token_max_market_cap)}\")\n",
    "print(f\"Filtering New Tokens for: {Master_Functions.days_back} days, {Master_Functions.hours_back} hours, {Master_Functions.minutes_back} minutes back\")\n",
    "print(f\"Token Launch Liquidity Filter: {Master_Functions.format_number(Master_Functions.new_token_liquidity_filter)}\")\n",
    "print(\"\\n--------------------------------\\n \\n Collecting New Token Listings...\\n \\n--------------------------------\\n\")\n",
    "\n",
    "\n",
    "\n",
    "#### New Token Listings Summary ####\n",
    "\n",
    "# Create the optimized folder structure\n",
    "data_folder = 'Data'\n",
    "new_token_data_folder = os.path.join(data_folder, 'New_Token_Data')\n",
    "current_date = datetime.now().strftime('%Y_%m_%d')  # Format: YYYY_MM_DD\n",
    "date_folder = os.path.join(new_token_data_folder, current_date)\n",
    "\n",
    "# Create subfolders for different data types\n",
    "ohlcv_folder = os.path.join(date_folder, 'OHLCV_Data')\n",
    "token_summary_folder = os.path.join(date_folder, 'Token_Summary')\n",
    "live_trades_folder = os.path.join(date_folder, 'Live_Trades')\n",
    "backtesting_results_folder = os.path.join(date_folder, 'Backtesting_Results')\n",
    "\n",
    "# Create a single timestamp for both Token_Summary and OHLCV_Data\n",
    "current_datetime = datetime.now().strftime('%Y_%b_%d_%I%M%p')  # Format: YYYY_Mon_DD_HHMM(AM/PM)\n",
    "ohlcv_datetime_folder = os.path.join(ohlcv_folder, current_datetime)\n",
    "token_summary_datetime_folder = os.path.join(token_summary_folder, current_datetime)\n",
    "\n",
    "# Create the folders if they don't exist\n",
    "for folder in [data_folder, new_token_data_folder, date_folder, ohlcv_datetime_folder, token_summary_datetime_folder, live_trades_folder, backtesting_results_folder]:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# Adjust days_back for the function call\n",
    "adjusted_days_back = Master_Functions.days_back + 1\n",
    "# Example usage:\n",
    "new_tokens = Master_Functions.get_new_listings(adjusted_days_back, Master_Functions.hours_back, Master_Functions.minutes_back, Master_Functions.API_Key, Master_Functions.new_token_liquidity_filter)\n",
    "new_tokens_filtered = new_tokens[1].rename(columns={\n",
    "    'address': 'Address'\n",
    "})\n",
    "\n",
    "# Get List of New Tokens Addresses\n",
    "new_tokens_address = new_tokens_filtered['Address'].tolist()\n",
    "\n",
    "# Set Index\n",
    "new_tokens_filtered = new_tokens_filtered.set_index('Address')\n",
    "\n",
    "# Get Token Overview Data\n",
    "token_overview_data = Master_Functions.get_token_trade_data_multi(new_tokens_address, Master_Functions.API_Key)\n",
    "\n",
    "# Get a list of all unique attributes across all DataFrames\n",
    "all_attributes = set()\n",
    "for token, df in token_overview_data.items():\n",
    "    if isinstance(df, pd.DataFrame) and not df.empty:\n",
    "        all_attributes.update(df['Attribute'].unique())\n",
    "\n",
    "# Convert the set to a sorted list\n",
    "columns_array = sorted(list(all_attributes))\n",
    "\n",
    "# Create the master DataFrame\n",
    "new_tokens_master_overview = pd.DataFrame(index=token_overview_data.keys(), columns=columns_array)\n",
    "\n",
    "# Fill the DataFrame with values\n",
    "for token, df in token_overview_data.items():\n",
    "    if isinstance(df, pd.DataFrame) and not df.empty:\n",
    "        for _, row in df.iterrows():\n",
    "            new_tokens_master_overview.at[token, row['Attribute']] = row['Value']\n",
    "\n",
    "# Set the index name to 'Address'\n",
    "new_tokens_master_overview.index.name = 'Address'\n",
    "\n",
    "# Filter out rows where 'Error' column is not NaN, if the column exists\n",
    "if 'Error' in new_tokens_master_overview.columns:\n",
    "    new_tokens_master_overview = new_tokens_master_overview[new_tokens_master_overview['Error'].isna()]\n",
    "new_tokens_master_overview[\"liquidityAddedAt\"] = new_tokens_filtered[\"liquidityAddedAt\"]\n",
    "new_tokens_filtered_overview = new_tokens_master_overview\n",
    "\n",
    "# Get the list of addresses from new_tokens_master_overview\n",
    "new_tokens_filtered_overview_address = new_tokens_filtered_overview.index.tolist()\n",
    "\n",
    "# Get market data for all tokens in new_tokens_master_overview_address\n",
    "market_data_list = []\n",
    "for address in new_tokens_filtered_overview_address:\n",
    "    market_data_df = Master_Functions.get_token_market_data(address, Master_Functions.API_Key)\n",
    "    if not market_data_df.empty:\n",
    "        market_data_list.append(market_data_df)\n",
    "\n",
    "# Combine all market data into a single DataFrame, filtering out empty DataFrames\n",
    "all_market_data_df = pd.concat([df for df in market_data_list if not df.empty], ignore_index=True)\n",
    "\n",
    "# Set 'Address' as the index\n",
    "all_market_data_df.set_index('Address', inplace=True)\n",
    "\n",
    "# Combine all_market_data_df and new_tokens_filtered_overview\n",
    "new_tokens_mc_added = new_tokens_filtered_overview.join(all_market_data_df, how='left')\n",
    "\n",
    "# Apply additional filters to new_tokens_mc_added\n",
    "new_tokens_mc_added = new_tokens_mc_added[\n",
    "    (new_tokens_mc_added['Liquidity'].astype(float) >= Master_Functions.new_token_min_liquidity) &\n",
    "    (new_tokens_mc_added['Liquidity'].astype(float) <= Master_Functions.new_token_max_liquidity) &\n",
    "    (new_tokens_mc_added['Market Cap'].astype(float) >= Master_Functions.new_token_min_market_cap) &\n",
    "    (new_tokens_mc_added['Market Cap'].astype(float) <= Master_Functions.new_token_max_market_cap)\n",
    "]\n",
    "\n",
    "# Save the filtered data with market cap range and time range in the filename\n",
    "mc_range = f\"{Master_Functions.new_token_min_market_cap/1e6:.1f}M-{Master_Functions.new_token_max_market_cap/1e6:.1f}M\"\n",
    "time_range = f\"{Master_Functions.days_back}d_{Master_Functions.hours_back}h_{Master_Functions.minutes_back}m\"\n",
    "filename = f\"new_tokens_mc_added_filtered_{mc_range}_{time_range}.csv\"\n",
    "file_path = os.path.join(token_summary_datetime_folder, filename)\n",
    "new_tokens_mc_added.to_csv(file_path)\n",
    "\n",
    "# Sort the DataFrame by 'Market Cap' in descending order\n",
    "new_tokens_mc_added_sorted = new_tokens_mc_added.sort_values(by='Market Cap', ascending=False)\n",
    "\n",
    "# Print each address with its corresponding Market Cap in descending order\n",
    "for address in new_tokens_mc_added_sorted.index:\n",
    "    market_cap = new_tokens_mc_added_sorted.at[address, 'Market Cap']\n",
    "    print(f\"https://dexscreener.com/solana/{address} - Market Cap: {Master_Functions.format_number(market_cap)}\")\n",
    "print(f\"\\nToken summary data saved to: {file_path}\")\n",
    "\n",
    "# Print the number of items in the \"Address\" column\n",
    "num_addresses = new_tokens_mc_added.index.size\n",
    "print(f\"\\nNumber of Tokens Filtered: {num_addresses}\")\n",
    "print(f\"\\n--------------------------------\\n \\nAll Token summary data saved to: {file_path}\\n \\n--------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeframes being used for OHLCV data: 1m, 3m, 5m, 15m, 30m, 1H, 4H, 1D\n",
      "Maximum starting market cap filter: $100,000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully retrieved 4P8apfoSyiwfgu4Gk3tx17igeP8s33ZfDTawfTEN3EQF - 1m data.\n",
      "\n",
      "Successfully retrieved 4P8apfoSyiwfgu4Gk3tx17igeP8s33ZfDTawfTEN3EQF - 3m data.\n",
      "\n",
      "Successfully retrieved 4P8apfoSyiwfgu4Gk3tx17igeP8s33ZfDTawfTEN3EQF - 5m data.\n",
      "\n",
      "Successfully retrieved 4P8apfoSyiwfgu4Gk3tx17igeP8s33ZfDTawfTEN3EQF - 15m data.\n",
      "\n",
      "Successfully retrieved 4P8apfoSyiwfgu4Gk3tx17igeP8s33ZfDTawfTEN3EQF - 30m data.\n",
      "\n",
      "Successfully retrieved 4P8apfoSyiwfgu4Gk3tx17igeP8s33ZfDTawfTEN3EQF - 1H data.\n",
      "\n",
      "Successfully retrieved 4P8apfoSyiwfgu4Gk3tx17igeP8s33ZfDTawfTEN3EQF - 4H data.\n",
      "\n",
      "Successfully retrieved 4P8apfoSyiwfgu4Gk3tx17igeP8s33ZfDTawfTEN3EQF - 1D data.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'marketCap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'marketCap'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m timeframe, df \u001b[38;5;129;01min\u001b[39;00m ohlcv_data[address]\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m---> 24\u001b[0m         start_market_cap \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmarketCap\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_market_cap \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m start_market_cap \u001b[38;5;241m>\u001b[39m Master_Functions\u001b[38;5;241m.\u001b[39mmax_start_market_cap:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'marketCap'"
     ]
    }
   ],
   "source": [
    "#### OHLCV Data Retrieval and Storage ####\n",
    "\n",
    "# Print the timeframes being used for OHLCV data\n",
    "print(f\"Timeframes being used to retrieve OHLCV data: {', '.join(Master_Functions.timeframes)}\")\n",
    "print(f\"\\n--------------------------------\\n\")\n",
    "\n",
    "# Get the list of token addresses\n",
    "token_addresses = new_tokens_mc_added.index.tolist()\n",
    "\n",
    "# Retrieve and save OHLCV data for each token and timeframe\n",
    "for address in token_addresses:\n",
    "    # Create a folder for the token\n",
    "    token_folder = os.path.join(ohlcv_datetime_folder, address)\n",
    "    os.makedirs(token_folder, exist_ok=True)\n",
    "    # Retrieve OHLCV data for all timeframes\n",
    "    ohlcv_data = Master_Functions.get_ohlcv_data_multi([address], Master_Functions.API_Key, Master_Functions.timeframes)\n",
    "    # Save OHLCV data for each timeframe\n",
    "    for timeframe, df in ohlcv_data[address].items():\n",
    "        if not df.empty:\n",
    "            filename = f\"{timeframe}.csv\"\n",
    "            file_path = os.path.join(token_folder, filename)\n",
    "            df.to_csv(file_path)\n",
    "            #print(f\"OHLCV data for {address} ({timeframe}) saved to: {file_path}\")\n",
    "            print(f\"OHLCV data retrieval and storage completed for {address} ({timeframe}).\")\n",
    "        else:\n",
    "            print(f\"No OHLCV data available for {address} ({timeframe})\")\n",
    "\n",
    "print(\"\\n--------------------------------\\nData Processing Complete\\n--------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import OHLCV Data and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing OHLCV data from folder: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM\n",
      "\n",
      "Structure of imported OHLCV data:\n",
      "{\n",
      "  \"5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump\": {\n",
      "    \"1m\": [\n",
      "      8,\n",
      "      7\n",
      "    ],\n",
      "    \"5m\": [\n",
      "      3,\n",
      "      7\n",
      "    ],\n",
      "    \"3m\": [\n",
      "      3,\n",
      "      7\n",
      "    ],\n",
      "    \"4H\": [\n",
      "      1,\n",
      "      7\n",
      "    ],\n",
      "    \"1H\": [\n",
      "      1,\n",
      "      7\n",
      "    ],\n",
      "    \"15m\": [\n",
      "      1,\n",
      "      7\n",
      "    ],\n",
      "    \"1D\": [\n",
      "      1,\n",
      "      7\n",
      "    ],\n",
      "    \"30m\": [\n",
      "      1,\n",
      "      7\n",
      "    ]\n",
      "  },\n",
      "  \"3bxVJsSkWHRZ4UeAg7N5YYxz8Z5AhpnrQj9Fe3wgpump\": {\n",
      "    \"1m\": [\n",
      "      9,\n",
      "      7\n",
      "    ],\n",
      "    \"5m\": [\n",
      "      3,\n",
      "      7\n",
      "    ],\n",
      "    \"3m\": [\n",
      "      3,\n",
      "      7\n",
      "    ],\n",
      "    \"4H\": [\n",
      "      1,\n",
      "      7\n",
      "    ],\n",
      "    \"1H\": [\n",
      "      1,\n",
      "      7\n",
      "    ],\n",
      "    \"15m\": [\n",
      "      1,\n",
      "      7\n",
      "    ],\n",
      "    \"1D\": [\n",
      "      1,\n",
      "      7\n",
      "    ],\n",
      "    \"30m\": [\n",
      "      1,\n",
      "      7\n",
      "    ]\n",
      "  },\n",
      "  \"788rZojRjiwvhTBqgzQvZHZKR84Cv5zzefVLr7kPpump\": {\n",
      "    \"1m\": [\n",
      "      4,\n",
      "      7\n",
      "    ],\n",
      "    \"5m\": [\n",
      "      2,\n",
      "      7\n",
      "    ],\n",
      "    \"3m\": [\n",
      "      2,\n",
      "      7\n",
      "    ],\n",
      "    \"4H\": [\n",
      "      1,\n",
      "      7\n",
      "    ],\n",
      "    \"1H\": [\n",
      "      1,\n",
      "      7\n",
      "    ],\n",
      "    \"15m\": [\n",
      "      1,\n",
      "      7\n",
      "    ],\n",
      "    \"1D\": [\n",
      "      1,\n",
      "      7\n",
      "    ],\n",
      "    \"30m\": [\n",
      "      1,\n",
      "      7\n",
      "    ]\n",
      "  },\n",
      "  \"2KsS85WYuksR6M9wEjGxgiNayoFdHdY4o7g5692Xpump\": {\n",
      "    \"1m\": [\n",
      "      6,\n",
      "      7\n",
      "    ],\n",
      "    \"5m\": [\n",
      "      2,\n",
      "      7\n",
      "    ],\n",
      "    \"3m\": [\n",
      "      2,\n",
      "      7\n",
      "    ],\n",
      "    \"4H\": [\n",
      "      1,\n",
      "      7\n",
      "    ],\n",
      "    \"1H\": [\n",
      "      1,\n",
      "      7\n",
      "    ],\n",
      "    \"15m\": [\n",
      "      1,\n",
      "      7\n",
      "    ],\n",
      "    \"1D\": [\n",
      "      1,\n",
      "      7\n",
      "    ],\n",
      "    \"30m\": [\n",
      "      1,\n",
      "      7\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n",
      "Example of accessing the data:\n",
      "Token: 5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump\n",
      "  Timeframe: 1m\n",
      "  Data shape: (8, 7)\n",
      "  First few rows:\n",
      "                                                          address     close  \\\n",
      "timestamp                                                                     \n",
      "2024-10-21 18:19:00  5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump  0.000072   \n",
      "2024-10-21 18:20:00  5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump  0.000114   \n",
      "2024-10-21 18:21:00  5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump  0.000107   \n",
      "2024-10-21 18:22:00  5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump  0.000048   \n",
      "2024-10-21 18:23:00  5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump  0.000052   \n",
      "\n",
      "                         high       low      open type        volume  \n",
      "timestamp                                                             \n",
      "2024-10-21 18:19:00  0.000134  0.000064  0.000064   1m  2.724036e+08  \n",
      "2024-10-21 18:20:00  0.000136  0.000067  0.000072   1m  6.180043e+08  \n",
      "2024-10-21 18:21:00  0.000178  0.000077  0.000114   1m  6.733344e+08  \n",
      "2024-10-21 18:22:00  0.000107  0.000046  0.000107   1m  5.070212e+08  \n",
      "2024-10-21 18:23:00  0.000052  0.000027  0.000048   1m  4.486848e+08  \n",
      "\n",
      "\n",
      "  Timeframe: 5m\n",
      "  Data shape: (3, 7)\n",
      "  First few rows:\n",
      "                                                          address     close  \\\n",
      "timestamp                                                                     \n",
      "2024-10-21 18:15:00  5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump  0.000072   \n",
      "2024-10-21 18:20:00  5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump  0.000027   \n",
      "2024-10-21 18:25:00  5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump  0.000014   \n",
      "\n",
      "                         high       low      open type        volume  \n",
      "timestamp                                                             \n",
      "2024-10-21 18:15:00  0.000134  0.000064  0.000064   5m  2.724036e+08  \n",
      "2024-10-21 18:20:00  0.000178  0.000025  0.000072   5m  2.638614e+09  \n",
      "2024-10-21 18:25:00  0.000042  0.000014  0.000027   5m  3.242045e+08  \n",
      "\n",
      "\n",
      "  Timeframe: 3m\n",
      "  Data shape: (3, 7)\n",
      "  First few rows:\n",
      "                                                          address     close  \\\n",
      "timestamp                                                                     \n",
      "2024-10-21 18:18:00  5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump  0.000114   \n",
      "2024-10-21 18:21:00  5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump  0.000052   \n",
      "2024-10-21 18:24:00  5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump  0.000014   \n",
      "\n",
      "                         high       low      open type        volume  \n",
      "timestamp                                                             \n",
      "2024-10-21 18:18:00  0.000136  0.000064  0.000064   3m  8.904078e+08  \n",
      "2024-10-21 18:21:00  0.000178  0.000027  0.000114   3m  1.629040e+09  \n",
      "2024-10-21 18:24:00  0.000055  0.000014  0.000052   3m  7.157734e+08  \n",
      "\n",
      "\n",
      "  Timeframe: 4H\n",
      "  Data shape: (1, 7)\n",
      "  First few rows:\n",
      "                                                          address     close  \\\n",
      "timestamp                                                                     \n",
      "2024-10-21 16:00:00  5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump  0.000014   \n",
      "\n",
      "                         high       low      open type        volume  \n",
      "timestamp                                                             \n",
      "2024-10-21 16:00:00  0.000178  0.000014  0.000064   4H  3.247865e+09  \n",
      "\n",
      "\n",
      "  Timeframe: 1H\n",
      "  Data shape: (1, 7)\n",
      "  First few rows:\n",
      "                                                          address     close  \\\n",
      "timestamp                                                                     \n",
      "2024-10-21 18:00:00  5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump  0.000014   \n",
      "\n",
      "                         high       low      open type        volume  \n",
      "timestamp                                                             \n",
      "2024-10-21 18:00:00  0.000178  0.000014  0.000064   1H  3.235222e+09  \n",
      "\n",
      "\n",
      "  Timeframe: 15m\n",
      "  Data shape: (1, 7)\n",
      "  First few rows:\n",
      "                                                          address     close  \\\n",
      "timestamp                                                                     \n",
      "2024-10-21 18:15:00  5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump  0.000014   \n",
      "\n",
      "                         high       low      open type        volume  \n",
      "timestamp                                                             \n",
      "2024-10-21 18:15:00  0.000178  0.000014  0.000064  15m  3.235222e+09  \n",
      "\n",
      "\n",
      "  Timeframe: 1D\n",
      "  Data shape: (1, 7)\n",
      "  First few rows:\n",
      "                                                 address     close      high  \\\n",
      "timestamp                                                                      \n",
      "2024-10-21  5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump  0.000014  0.000178   \n",
      "\n",
      "                 low      open type        volume  \n",
      "timestamp                                          \n",
      "2024-10-21  0.000014  0.000064   1D  3.247865e+09  \n",
      "\n",
      "\n",
      "  Timeframe: 30m\n",
      "  Data shape: (1, 7)\n",
      "  First few rows:\n",
      "                                                          address     close  \\\n",
      "timestamp                                                                     \n",
      "2024-10-21 18:00:00  5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump  0.000014   \n",
      "\n",
      "                         high       low      open type        volume  \n",
      "timestamp                                                             \n",
      "2024-10-21 18:00:00  0.000178  0.000014  0.000064  30m  3.235222e+09  \n",
      "\n",
      "\n",
      "\n",
      "Calculated metrics:\n",
      "Token: 5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump\n",
      "  Timeframe: 1m\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: -80.65%\n",
      "    Volatility: 47.35%\n",
      "  Timeframe: 5m\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: -80.65%\n",
      "    Volatility: 9.21%\n",
      "  Timeframe: 3m\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: -87.80%\n",
      "    Volatility: 13.67%\n",
      "  Timeframe: 4H\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "  Timeframe: 1H\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "  Timeframe: 15m\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "  Timeframe: 1D\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "  Timeframe: 30m\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "\n",
      "\n",
      "Token: 3bxVJsSkWHRZ4UeAg7N5YYxz8Z5AhpnrQj9Fe3wgpump\n",
      "  Timeframe: 1m\n",
      "    Last Price: 0.0001\n",
      "    Daily Return: -48.57%\n",
      "    Volatility: 27.87%\n",
      "  Timeframe: 5m\n",
      "    Last Price: 0.0001\n",
      "    Daily Return: -2.76%\n",
      "    Volatility: 23.69%\n",
      "  Timeframe: 3m\n",
      "    Last Price: 0.0001\n",
      "    Daily Return: 84.65%\n",
      "    Volatility: 34.44%\n",
      "  Timeframe: 4H\n",
      "    Last Price: 0.0001\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "  Timeframe: 1H\n",
      "    Last Price: 0.0001\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "  Timeframe: 15m\n",
      "    Last Price: 0.0001\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "  Timeframe: 1D\n",
      "    Last Price: 0.0001\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "  Timeframe: 30m\n",
      "    Last Price: 0.0001\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "\n",
      "\n",
      "Token: 788rZojRjiwvhTBqgzQvZHZKR84Cv5zzefVLr7kPpump\n",
      "  Timeframe: 1m\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: -0.10%\n",
      "    Volatility: 33.53%\n",
      "  Timeframe: 5m\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: -5.64%\n",
      "    Volatility: nan%\n",
      "  Timeframe: 3m\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: 4.53%\n",
      "    Volatility: nan%\n",
      "  Timeframe: 4H\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "  Timeframe: 1H\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "  Timeframe: 15m\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "  Timeframe: 1D\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "  Timeframe: 30m\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "\n",
      "\n",
      "Token: 2KsS85WYuksR6M9wEjGxgiNayoFdHdY4o7g5692Xpump\n",
      "  Timeframe: 1m\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: -79.10%\n",
      "    Volatility: 67.21%\n",
      "  Timeframe: 5m\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: -58.81%\n",
      "    Volatility: nan%\n",
      "  Timeframe: 3m\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: -39.44%\n",
      "    Volatility: nan%\n",
      "  Timeframe: 4H\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "  Timeframe: 1H\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "  Timeframe: 15m\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "  Timeframe: 1D\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "  Timeframe: 30m\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the most recent folder\n",
    "base_path = 'Data/New_Token_Data'\n",
    "current_date = datetime.now().strftime('%Y_%m_%d')\n",
    "date_folder = os.path.join(base_path, current_date)\n",
    "ohlcv_folder = os.path.join(date_folder, 'OHLCV_Data')\n",
    "ohlcv_datetime_folder = Master_Functions.get_most_recent_folder(ohlcv_folder)\n",
    "\n",
    "# Print the name of the folder being used for import\n",
    "print(f\"Importing OHLCV data from folder: {ohlcv_datetime_folder}\")\n",
    "\n",
    "# Import the OHLCV data\n",
    "imported_ohlcv_data = Master_Functions.import_ohlcv_data(ohlcv_datetime_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
