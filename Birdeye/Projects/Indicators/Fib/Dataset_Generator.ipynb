{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtesting Fibonacci Retracement Post Wave 1 Peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"success\":true,\"data\":[\"solana\",\"ethereum\",\"arbitrum\",\"avalanche\",\"bsc\",\"optimism\",\"polygon\",\"base\",\"zksync\"]}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Path to Master Functions and Keys\n",
    "current_dir = os.getcwd()\n",
    "root_dir = os.path.abspath(os.path.join(current_dir, '..', '..', '..', '..'))\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "import Birdeye.Basics.Master_Functions as Master_Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wallet and API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_Key = Master_Functions.API_Key\n",
    "wallet = Master_Functions.wallet\n",
    "chain = Master_Functions.chain # Choose between: solana,ethereum,arbitrum,avalanche,bsc,optimism,polygon,base,zksync\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Tokens by Market Cap Range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Established Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsort_by = \"mc\"  # mc, v24hUSD, v24hChangePercent \\nsort_type = \"desc\"  # asc, desc\\nmin_liquidity = 100000  # Minimum liquidity in USD (100k)\\nmin_volume_24h = 1000000  # Minimum 24-hour trading volume in USD\\nmin_market_cap = 1000000  # Minimum market cap in USD (1 million)\\nmax_market_cap = 900000000  # Maximum market cap in USD (900 million)\\ntotal_tokens = 300  # Change this to the number of tokens you want to retrieve\\n\\n# Get the list of established tokens\\nestablished_tokens_filtered = Master_Functions.get_token_list(sort_by, sort_type, min_liquidity, min_volume_24h, min_market_cap, max_market_cap, total_tokens, chain, API_Key)\\n#print(established_tokens_filtered)\\n\\n# Set the index to \\'Address\\'\\nestablished_tokens_filtered = established_tokens_filtered.set_index(\\'Address\\')\\n\\n# Get the list of addresses\\nestablished_tokens_addresses = established_tokens_filtered.index.tolist()\\n\\n# Get Token Overview Data for established tokens\\nestablished_tokens_data = Master_Functions.get_token_trade_data_multi(established_tokens_addresses, API_Key)\\n\\n# Get a list of all unique attributes across all DataFrames\\nall_attributes = set()\\nfor token, df in established_tokens_data.items():\\n    if isinstance(df, pd.DataFrame) and not df.empty:\\n        all_attributes.update(df[\\'Attribute\\'].unique())\\n\\n# Convert the set to a sorted list\\ncolumns_array = sorted(list(all_attributes))\\n\\n# Create the master DataFrame\\nestablished_tokens_master_overview = pd.DataFrame(index=established_tokens_data.keys(), columns=columns_array)\\n\\n# Fill the DataFrame with values\\nfor token, df in established_tokens_data.items():\\n    if isinstance(df, pd.DataFrame) and not df.empty:\\n        for _, row in df.iterrows():\\n            established_tokens_master_overview.at[token, row[\\'Attribute\\']] = row[\\'Value\\']\\n\\n# Set the index name to \\'Address\\'\\nestablished_tokens_master_overview.index.name = \\'Address\\'\\n\\n# Optional: Save to CSV\\nestablished_tokens_master_overview.to_csv(\\'Data/established_tokens_master_overview.csv\\')\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "sort_by = \"mc\"  # mc, v24hUSD, v24hChangePercent \n",
    "sort_type = \"desc\"  # asc, desc\n",
    "min_liquidity = 100000  # Minimum liquidity in USD (100k)\n",
    "min_volume_24h = 1000000  # Minimum 24-hour trading volume in USD\n",
    "min_market_cap = 1000000  # Minimum market cap in USD (1 million)\n",
    "max_market_cap = 900000000  # Maximum market cap in USD (900 million)\n",
    "total_tokens = 300  # Change this to the number of tokens you want to retrieve\n",
    "\n",
    "# Get the list of established tokens\n",
    "established_tokens_filtered = Master_Functions.get_token_list(sort_by, sort_type, min_liquidity, min_volume_24h, min_market_cap, max_market_cap, total_tokens, chain, API_Key)\n",
    "#print(established_tokens_filtered)\n",
    "\n",
    "# Set the index to 'Address'\n",
    "established_tokens_filtered = established_tokens_filtered.set_index('Address')\n",
    "\n",
    "# Get the list of addresses\n",
    "established_tokens_addresses = established_tokens_filtered.index.tolist()\n",
    "\n",
    "# Get Token Overview Data for established tokens\n",
    "established_tokens_data = Master_Functions.get_token_trade_data_multi(established_tokens_addresses, API_Key)\n",
    "\n",
    "# Get a list of all unique attributes across all DataFrames\n",
    "all_attributes = set()\n",
    "for token, df in established_tokens_data.items():\n",
    "    if isinstance(df, pd.DataFrame) and not df.empty:\n",
    "        all_attributes.update(df['Attribute'].unique())\n",
    "\n",
    "# Convert the set to a sorted list\n",
    "columns_array = sorted(list(all_attributes))\n",
    "\n",
    "# Create the master DataFrame\n",
    "established_tokens_master_overview = pd.DataFrame(index=established_tokens_data.keys(), columns=columns_array)\n",
    "\n",
    "# Fill the DataFrame with values\n",
    "for token, df in established_tokens_data.items():\n",
    "    if isinstance(df, pd.DataFrame) and not df.empty:\n",
    "        for _, row in df.iterrows():\n",
    "            established_tokens_master_overview.at[token, row['Attribute']] = row['Value']\n",
    "\n",
    "# Set the index name to 'Address'\n",
    "established_tokens_master_overview.index.name = 'Address'\n",
    "\n",
    "# Optional: Save to CSV\n",
    "established_tokens_master_overview.to_csv('Data/established_tokens_master_overview.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Token Listings Summary + OHLCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering New Tokens for: 0 days, 0 hours, 10 minutes back\n",
      "Base Liquidity Filter: 10K\n",
      "Min Liquidity: 10K\n",
      "Max Liquidity: 100K\n",
      "Min Market Cap: 10K\n",
      "Max Market Cap: 300K\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 65\u001b[0m\n\u001b[1;32m     63\u001b[0m all_attributes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token, df \u001b[38;5;129;01min\u001b[39;00m token_overview_data\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(df, \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m     66\u001b[0m         all_attributes\u001b[38;5;241m.\u001b[39mupdate(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttribute\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Convert the set to a sorted list\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Filters for new tokens\n",
    "days_back = 0  # 0 for last 24 hours, 1 for 24-48 hours ago, 2 for 48-72 hours ago (max 2)\n",
    "hours_back = 0  # 0-23 hours back within the selected day\n",
    "minutes_back = 10  # 0-59 minutes back within the selected hour\n",
    "\n",
    "new_token_liquidity_filter = 10000\n",
    "\n",
    "# New token specific filters\n",
    "new_token_min_liquidity = 10000  # Minimum liquidity in USD for new tokens\n",
    "new_token_max_liquidity = 100000  # Maximum liquidity in USD for new tokens\n",
    "new_token_min_market_cap = 10000  # Minimum market cap in USD for new tokens\n",
    "new_token_max_market_cap = 300000  # Maximum market cap in USD for new tokens\n",
    "\n",
    "# Print the filters being used\n",
    "print(f\"Filtering New Tokens for: {days_back} days, {hours_back} hours, {minutes_back} minutes back\")\n",
    "print(f\"Base Liquidity Filter: {Master_Functions.format_number(new_token_liquidity_filter)}\")\n",
    "print(f\"Min Liquidity: {Master_Functions.format_number(new_token_min_liquidity)}\")\n",
    "print(f\"Max Liquidity: {Master_Functions.format_number(new_token_max_liquidity)}\")\n",
    "print(f\"Min Market Cap: {Master_Functions.format_number(new_token_min_market_cap)}\")\n",
    "print(f\"Max Market Cap: {Master_Functions.format_number(new_token_max_market_cap)}\")\n",
    "\n",
    "# Create the optimized folder structure\n",
    "data_folder = 'Data'\n",
    "new_token_data_folder = os.path.join(data_folder, 'New_Token_Data')\n",
    "current_date = datetime.now().strftime('%Y_%m_%d')  # Format: YYYY_MM_DD\n",
    "date_folder = os.path.join(new_token_data_folder, current_date)\n",
    "\n",
    "# Create subfolders for different data types\n",
    "ohlcv_folder = os.path.join(date_folder, 'OHLCV_Data')\n",
    "token_summary_folder = os.path.join(date_folder, 'Token_Summary')\n",
    "live_trades_folder = os.path.join(date_folder, 'Live_Trades')\n",
    "backtesting_results_folder = os.path.join(date_folder, 'Backtesting_Results')\n",
    "\n",
    "# Create a single timestamp for both Token_Summary and OHLCV_Data\n",
    "current_datetime = datetime.now().strftime('%Y_%b_%d_%I%M%p')  # Format: YYYY_Mon_DD_HHMM(AM/PM)\n",
    "ohlcv_datetime_folder = os.path.join(ohlcv_folder, current_datetime)\n",
    "token_summary_datetime_folder = os.path.join(token_summary_folder, current_datetime)\n",
    "\n",
    "# Create the folders if they don't exist\n",
    "for folder in [data_folder, new_token_data_folder, date_folder, ohlcv_datetime_folder, token_summary_datetime_folder, live_trades_folder, backtesting_results_folder]:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# Adjust days_back for the function call\n",
    "adjusted_days_back = days_back + 1\n",
    "\n",
    "# Example usage:\n",
    "new_tokens = Master_Functions.get_new_listings(adjusted_days_back, hours_back, minutes_back, API_Key, new_token_liquidity_filter)\n",
    "\n",
    "new_tokens_filtered = new_tokens[1].rename(columns={\n",
    "    'address': 'Address'\n",
    "})\n",
    "\n",
    "# Get List of New Tokens Addresses\n",
    "new_tokens_address = new_tokens_filtered['Address'].tolist()\n",
    "\n",
    "# Set Index\n",
    "new_tokens_filtered = new_tokens_filtered.set_index('Address')\n",
    "\n",
    "# Get Token Overview Data\n",
    "token_overview_data = Master_Functions.get_token_trade_data_multi(new_tokens_address, API_Key)\n",
    "\n",
    "# Get a list of all unique attributes across all DataFrames\n",
    "all_attributes = set()\n",
    "for token, df in token_overview_data.items():\n",
    "    if isinstance(df, pd.DataFrame) and not df.empty:\n",
    "        all_attributes.update(df['Attribute'].unique())\n",
    "\n",
    "# Convert the set to a sorted list\n",
    "columns_array = sorted(list(all_attributes))\n",
    "\n",
    "# Create the master DataFrame\n",
    "new_tokens_master_overview = pd.DataFrame(index=token_overview_data.keys(), columns=columns_array)\n",
    "\n",
    "# Fill the DataFrame with values\n",
    "for token, df in token_overview_data.items():\n",
    "    if isinstance(df, pd.DataFrame) and not df.empty:\n",
    "        for _, row in df.iterrows():\n",
    "            new_tokens_master_overview.at[token, row['Attribute']] = row['Value']\n",
    "\n",
    "# Set the index name to 'Address'\n",
    "new_tokens_master_overview.index.name = 'Address'\n",
    "\n",
    "# Filter out rows where 'Error' column is not NaN, if the column exists\n",
    "if 'Error' in new_tokens_master_overview.columns:\n",
    "    new_tokens_master_overview = new_tokens_master_overview[new_tokens_master_overview['Error'].isna()]\n",
    "\n",
    "new_tokens_master_overview[\"liquidityAddedAt\"] = new_tokens_filtered[\"liquidityAddedAt\"]\n",
    "\n",
    "new_tokens_filtered_overview = new_tokens_master_overview\n",
    "\n",
    "# Get the list of addresses from new_tokens_master_overview\n",
    "new_tokens_filtered_overview_address = new_tokens_filtered_overview.index.tolist()\n",
    "\n",
    "# Get market data for all tokens in new_tokens_master_overview_address\n",
    "market_data_list = []\n",
    "\n",
    "for address in new_tokens_filtered_overview_address:\n",
    "    market_data_df = Master_Functions.get_token_market_data(address, API_Key)\n",
    "    if not market_data_df.empty:\n",
    "        market_data_list.append(market_data_df)\n",
    "\n",
    "# Combine all market data into a single DataFrame, filtering out empty DataFrames\n",
    "all_market_data_df = pd.concat([df for df in market_data_list if not df.empty], ignore_index=True)\n",
    "\n",
    "# Set 'Address' as the index\n",
    "all_market_data_df.set_index('Address', inplace=True)\n",
    "\n",
    "# Combine all_market_data_df and new_tokens_filtered_overview\n",
    "new_tokens_mc_added = new_tokens_filtered_overview.join(all_market_data_df, how='left')\n",
    "\n",
    "# Apply additional filters to new_tokens_mc_added\n",
    "new_tokens_mc_added = new_tokens_mc_added[\n",
    "    (new_tokens_mc_added['Liquidity'].astype(float) >= new_token_min_liquidity) &\n",
    "    (new_tokens_mc_added['Liquidity'].astype(float) <= new_token_max_liquidity) &\n",
    "    (new_tokens_mc_added['Market Cap'].astype(float) >= new_token_min_market_cap) &\n",
    "    (new_tokens_mc_added['Market Cap'].astype(float) <= new_token_max_market_cap)\n",
    "]\n",
    "\n",
    "# Save the filtered data with market cap range and time range in the filename\n",
    "mc_range = f\"{new_token_min_market_cap/1e6:.1f}M-{new_token_max_market_cap/1e6:.1f}M\"\n",
    "time_range = f\"{days_back}d_{hours_back}h_{minutes_back}m\"\n",
    "filename = f\"new_tokens_mc_added_filtered_{mc_range}_{time_range}.csv\"\n",
    "file_path = os.path.join(token_summary_datetime_folder, filename)\n",
    "new_tokens_mc_added.to_csv(file_path)\n",
    "\n",
    "print(f\"Token summary data saved to: {file_path}\")\n",
    "\n",
    "# Print the number of items in the \"Address\" column\n",
    "num_addresses = new_tokens_mc_added.index.size\n",
    "print(f\"Number of Tokens Filtered: {num_addresses}\")\n",
    "\n",
    "# Sort the DataFrame by 'Market Cap' in descending order\n",
    "new_tokens_mc_added_sorted = new_tokens_mc_added.sort_values(by='Market Cap', ascending=False)\n",
    "\n",
    "# Print each address with its corresponding Market Cap in descending order\n",
    "for address in new_tokens_mc_added_sorted.index:\n",
    "    market_cap = new_tokens_mc_added_sorted.at[address, 'Market Cap']\n",
    "    print(f\"https://dexscreener.com/solana/{address} - Market Cap: {Master_Functions.format_number(market_cap)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeframes being used for OHLCV data: 1m, 3m, 5m, 15m, 30m, 1H, 4H, 1D\n",
      "\n",
      "Successfully retrieved 788rZojRjiwvhTBqgzQvZHZKR84Cv5zzefVLr7kPpump - 1m data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully retrieved 788rZojRjiwvhTBqgzQvZHZKR84Cv5zzefVLr7kPpump - 3m data.\n",
      "\n",
      "Successfully retrieved 788rZojRjiwvhTBqgzQvZHZKR84Cv5zzefVLr7kPpump - 5m data.\n",
      "\n",
      "Successfully retrieved 788rZojRjiwvhTBqgzQvZHZKR84Cv5zzefVLr7kPpump - 15m data.\n",
      "\n",
      "Successfully retrieved 788rZojRjiwvhTBqgzQvZHZKR84Cv5zzefVLr7kPpump - 30m data.\n",
      "\n",
      "Successfully retrieved 788rZojRjiwvhTBqgzQvZHZKR84Cv5zzefVLr7kPpump - 1H data.\n",
      "\n",
      "Successfully retrieved 788rZojRjiwvhTBqgzQvZHZKR84Cv5zzefVLr7kPpump - 4H data.\n",
      "\n",
      "Successfully retrieved 788rZojRjiwvhTBqgzQvZHZKR84Cv5zzefVLr7kPpump - 1D data.\n",
      "OHLCV data for 788rZojRjiwvhTBqgzQvZHZKR84Cv5zzefVLr7kPpump (1m) saved to: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM/788rZojRjiwvhTBqgzQvZHZKR84Cv5zzefVLr7kPpump/1m.csv\n",
      "OHLCV data for 788rZojRjiwvhTBqgzQvZHZKR84Cv5zzefVLr7kPpump (3m) saved to: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM/788rZojRjiwvhTBqgzQvZHZKR84Cv5zzefVLr7kPpump/3m.csv\n",
      "OHLCV data for 788rZojRjiwvhTBqgzQvZHZKR84Cv5zzefVLr7kPpump (5m) saved to: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM/788rZojRjiwvhTBqgzQvZHZKR84Cv5zzefVLr7kPpump/5m.csv\n",
      "OHLCV data for 788rZojRjiwvhTBqgzQvZHZKR84Cv5zzefVLr7kPpump (15m) saved to: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM/788rZojRjiwvhTBqgzQvZHZKR84Cv5zzefVLr7kPpump/15m.csv\n",
      "OHLCV data for 788rZojRjiwvhTBqgzQvZHZKR84Cv5zzefVLr7kPpump (30m) saved to: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM/788rZojRjiwvhTBqgzQvZHZKR84Cv5zzefVLr7kPpump/30m.csv\n",
      "OHLCV data for 788rZojRjiwvhTBqgzQvZHZKR84Cv5zzefVLr7kPpump (1H) saved to: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM/788rZojRjiwvhTBqgzQvZHZKR84Cv5zzefVLr7kPpump/1H.csv\n",
      "OHLCV data for 788rZojRjiwvhTBqgzQvZHZKR84Cv5zzefVLr7kPpump (4H) saved to: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM/788rZojRjiwvhTBqgzQvZHZKR84Cv5zzefVLr7kPpump/4H.csv\n",
      "OHLCV data for 788rZojRjiwvhTBqgzQvZHZKR84Cv5zzefVLr7kPpump (1D) saved to: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM/788rZojRjiwvhTBqgzQvZHZKR84Cv5zzefVLr7kPpump/1D.csv\n",
      "\n",
      "Successfully retrieved 2KsS85WYuksR6M9wEjGxgiNayoFdHdY4o7g5692Xpump - 1m data.\n",
      "\n",
      "Successfully retrieved 2KsS85WYuksR6M9wEjGxgiNayoFdHdY4o7g5692Xpump - 3m data.\n",
      "\n",
      "Successfully retrieved 2KsS85WYuksR6M9wEjGxgiNayoFdHdY4o7g5692Xpump - 5m data.\n",
      "\n",
      "Successfully retrieved 2KsS85WYuksR6M9wEjGxgiNayoFdHdY4o7g5692Xpump - 15m data.\n",
      "\n",
      "Successfully retrieved 2KsS85WYuksR6M9wEjGxgiNayoFdHdY4o7g5692Xpump - 30m data.\n",
      "\n",
      "Successfully retrieved 2KsS85WYuksR6M9wEjGxgiNayoFdHdY4o7g5692Xpump - 1H data.\n",
      "\n",
      "Successfully retrieved 2KsS85WYuksR6M9wEjGxgiNayoFdHdY4o7g5692Xpump - 4H data.\n",
      "\n",
      "Successfully retrieved 2KsS85WYuksR6M9wEjGxgiNayoFdHdY4o7g5692Xpump - 1D data.\n",
      "OHLCV data for 2KsS85WYuksR6M9wEjGxgiNayoFdHdY4o7g5692Xpump (1m) saved to: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM/2KsS85WYuksR6M9wEjGxgiNayoFdHdY4o7g5692Xpump/1m.csv\n",
      "OHLCV data for 2KsS85WYuksR6M9wEjGxgiNayoFdHdY4o7g5692Xpump (3m) saved to: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM/2KsS85WYuksR6M9wEjGxgiNayoFdHdY4o7g5692Xpump/3m.csv\n",
      "OHLCV data for 2KsS85WYuksR6M9wEjGxgiNayoFdHdY4o7g5692Xpump (5m) saved to: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM/2KsS85WYuksR6M9wEjGxgiNayoFdHdY4o7g5692Xpump/5m.csv\n",
      "OHLCV data for 2KsS85WYuksR6M9wEjGxgiNayoFdHdY4o7g5692Xpump (15m) saved to: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM/2KsS85WYuksR6M9wEjGxgiNayoFdHdY4o7g5692Xpump/15m.csv\n",
      "OHLCV data for 2KsS85WYuksR6M9wEjGxgiNayoFdHdY4o7g5692Xpump (30m) saved to: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM/2KsS85WYuksR6M9wEjGxgiNayoFdHdY4o7g5692Xpump/30m.csv\n",
      "OHLCV data for 2KsS85WYuksR6M9wEjGxgiNayoFdHdY4o7g5692Xpump (1H) saved to: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM/2KsS85WYuksR6M9wEjGxgiNayoFdHdY4o7g5692Xpump/1H.csv\n",
      "OHLCV data for 2KsS85WYuksR6M9wEjGxgiNayoFdHdY4o7g5692Xpump (4H) saved to: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM/2KsS85WYuksR6M9wEjGxgiNayoFdHdY4o7g5692Xpump/4H.csv\n",
      "OHLCV data for 2KsS85WYuksR6M9wEjGxgiNayoFdHdY4o7g5692Xpump (1D) saved to: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM/2KsS85WYuksR6M9wEjGxgiNayoFdHdY4o7g5692Xpump/1D.csv\n",
      "\n",
      "Successfully retrieved 5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump - 1m data.\n",
      "\n",
      "Successfully retrieved 5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump - 3m data.\n",
      "\n",
      "Successfully retrieved 5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump - 5m data.\n",
      "\n",
      "Successfully retrieved 5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump - 15m data.\n",
      "\n",
      "Successfully retrieved 5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump - 30m data.\n",
      "\n",
      "Successfully retrieved 5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump - 1H data.\n",
      "\n",
      "Successfully retrieved 5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump - 4H data.\n",
      "\n",
      "Successfully retrieved 5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump - 1D data.\n",
      "OHLCV data for 5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump (1m) saved to: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM/5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump/1m.csv\n",
      "OHLCV data for 5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump (3m) saved to: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM/5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump/3m.csv\n",
      "OHLCV data for 5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump (5m) saved to: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM/5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump/5m.csv\n",
      "OHLCV data for 5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump (15m) saved to: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM/5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump/15m.csv\n",
      "OHLCV data for 5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump (30m) saved to: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM/5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump/30m.csv\n",
      "OHLCV data for 5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump (1H) saved to: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM/5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump/1H.csv\n",
      "OHLCV data for 5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump (4H) saved to: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM/5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump/4H.csv\n",
      "OHLCV data for 5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump (1D) saved to: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM/5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump/1D.csv\n",
      "\n",
      "Successfully retrieved 3bxVJsSkWHRZ4UeAg7N5YYxz8Z5AhpnrQj9Fe3wgpump - 1m data.\n",
      "\n",
      "Successfully retrieved 3bxVJsSkWHRZ4UeAg7N5YYxz8Z5AhpnrQj9Fe3wgpump - 3m data.\n",
      "\n",
      "Successfully retrieved 3bxVJsSkWHRZ4UeAg7N5YYxz8Z5AhpnrQj9Fe3wgpump - 5m data.\n",
      "\n",
      "Successfully retrieved 3bxVJsSkWHRZ4UeAg7N5YYxz8Z5AhpnrQj9Fe3wgpump - 15m data.\n",
      "\n",
      "Successfully retrieved 3bxVJsSkWHRZ4UeAg7N5YYxz8Z5AhpnrQj9Fe3wgpump - 30m data.\n",
      "\n",
      "Successfully retrieved 3bxVJsSkWHRZ4UeAg7N5YYxz8Z5AhpnrQj9Fe3wgpump - 1H data.\n",
      "\n",
      "Successfully retrieved 3bxVJsSkWHRZ4UeAg7N5YYxz8Z5AhpnrQj9Fe3wgpump - 4H data.\n",
      "\n",
      "Successfully retrieved 3bxVJsSkWHRZ4UeAg7N5YYxz8Z5AhpnrQj9Fe3wgpump - 1D data.\n",
      "OHLCV data for 3bxVJsSkWHRZ4UeAg7N5YYxz8Z5AhpnrQj9Fe3wgpump (1m) saved to: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM/3bxVJsSkWHRZ4UeAg7N5YYxz8Z5AhpnrQj9Fe3wgpump/1m.csv\n",
      "OHLCV data for 3bxVJsSkWHRZ4UeAg7N5YYxz8Z5AhpnrQj9Fe3wgpump (3m) saved to: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM/3bxVJsSkWHRZ4UeAg7N5YYxz8Z5AhpnrQj9Fe3wgpump/3m.csv\n",
      "OHLCV data for 3bxVJsSkWHRZ4UeAg7N5YYxz8Z5AhpnrQj9Fe3wgpump (5m) saved to: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM/3bxVJsSkWHRZ4UeAg7N5YYxz8Z5AhpnrQj9Fe3wgpump/5m.csv\n",
      "OHLCV data for 3bxVJsSkWHRZ4UeAg7N5YYxz8Z5AhpnrQj9Fe3wgpump (15m) saved to: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM/3bxVJsSkWHRZ4UeAg7N5YYxz8Z5AhpnrQj9Fe3wgpump/15m.csv\n",
      "OHLCV data for 3bxVJsSkWHRZ4UeAg7N5YYxz8Z5AhpnrQj9Fe3wgpump (30m) saved to: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM/3bxVJsSkWHRZ4UeAg7N5YYxz8Z5AhpnrQj9Fe3wgpump/30m.csv\n",
      "OHLCV data for 3bxVJsSkWHRZ4UeAg7N5YYxz8Z5AhpnrQj9Fe3wgpump (1H) saved to: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM/3bxVJsSkWHRZ4UeAg7N5YYxz8Z5AhpnrQj9Fe3wgpump/1H.csv\n",
      "OHLCV data for 3bxVJsSkWHRZ4UeAg7N5YYxz8Z5AhpnrQj9Fe3wgpump (4H) saved to: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM/3bxVJsSkWHRZ4UeAg7N5YYxz8Z5AhpnrQj9Fe3wgpump/4H.csv\n",
      "OHLCV data for 3bxVJsSkWHRZ4UeAg7N5YYxz8Z5AhpnrQj9Fe3wgpump (1D) saved to: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM/3bxVJsSkWHRZ4UeAg7N5YYxz8Z5AhpnrQj9Fe3wgpump/1D.csv\n",
      "OHLCV data retrieval and storage completed.\n"
     ]
    }
   ],
   "source": [
    "# OHLCV Data Retrieval and Storage\n",
    "\n",
    "# Define the timeframes for OHLCV data (1 hour and under)\n",
    "timeframes = ['1m', '3m', '5m', '15m', '30m', '1H', '4H', '1D'] \n",
    "# ['1m', '3m', '5m', '15m', '30m', '1H', '2H', '4H', '6H', '8H', '12H', '1D']\n",
    "\n",
    "# Print the timeframes being used for OHLCV data\n",
    "print(f\"Timeframes being used for OHLCV data: {', '.join(timeframes)}\")\n",
    "\n",
    "# Get the list of token addresses\n",
    "token_addresses = new_tokens_mc_added.index.tolist()\n",
    "\n",
    "# Retrieve and save OHLCV data for each token and timeframe\n",
    "for address in token_addresses:\n",
    "    # Create a folder for the token\n",
    "    token_folder = os.path.join(ohlcv_datetime_folder, address)\n",
    "    os.makedirs(token_folder, exist_ok=True)\n",
    "    \n",
    "    # Retrieve OHLCV data for all timeframes\n",
    "    ohlcv_data = Master_Functions.get_ohlcv_data_multi([address], API_Key, timeframes=timeframes)\n",
    "    \n",
    "    # Save OHLCV data for each timeframe\n",
    "    for timeframe, df in ohlcv_data[address].items():\n",
    "        if not df.empty:\n",
    "            filename = f\"{timeframe}.csv\"\n",
    "            file_path = os.path.join(token_folder, filename)\n",
    "            df.to_csv(file_path)\n",
    "            print(f\"OHLCV data for {address} ({timeframe}) saved to: {file_path}\")\n",
    "        else:\n",
    "            print(f\"No OHLCV data available for {address} ({timeframe})\")\n",
    "\n",
    "print(\"OHLCV data retrieval and storage completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import OHLCV Data and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing OHLCV data from folder: Data/New_Token_Data/2024_10_21/OHLCV_Data/2024_Oct_21_0626PM\n",
      "\n",
      "Structure of imported OHLCV data:\n",
      "{\n",
      "  \"5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump\": {\n",
      "    \"1m\": [\n",
      "      8,\n",
      "      7\n",
      "    ],\n",
      "    \"5m\": [\n",
      "      3,\n",
      "      7\n",
      "    ],\n",
      "    \"3m\": [\n",
      "      3,\n",
      "      7\n",
      "    ],\n",
      "    \"4H\": [\n",
      "      1,\n",
      "      7\n",
      "    ],\n",
      "    \"1H\": [\n",
      "      1,\n",
      "      7\n",
      "    ],\n",
      "    \"15m\": [\n",
      "      1,\n",
      "      7\n",
      "    ],\n",
      "    \"1D\": [\n",
      "      1,\n",
      "      7\n",
      "    ],\n",
      "    \"30m\": [\n",
      "      1,\n",
      "      7\n",
      "    ]\n",
      "  },\n",
      "  \"3bxVJsSkWHRZ4UeAg7N5YYxz8Z5AhpnrQj9Fe3wgpump\": {\n",
      "    \"1m\": [\n",
      "      9,\n",
      "      7\n",
      "    ],\n",
      "    \"5m\": [\n",
      "      3,\n",
      "      7\n",
      "    ],\n",
      "    \"3m\": [\n",
      "      3,\n",
      "      7\n",
      "    ],\n",
      "    \"4H\": [\n",
      "      1,\n",
      "      7\n",
      "    ],\n",
      "    \"1H\": [\n",
      "      1,\n",
      "      7\n",
      "    ],\n",
      "    \"15m\": [\n",
      "      1,\n",
      "      7\n",
      "    ],\n",
      "    \"1D\": [\n",
      "      1,\n",
      "      7\n",
      "    ],\n",
      "    \"30m\": [\n",
      "      1,\n",
      "      7\n",
      "    ]\n",
      "  },\n",
      "  \"788rZojRjiwvhTBqgzQvZHZKR84Cv5zzefVLr7kPpump\": {\n",
      "    \"1m\": [\n",
      "      4,\n",
      "      7\n",
      "    ],\n",
      "    \"5m\": [\n",
      "      2,\n",
      "      7\n",
      "    ],\n",
      "    \"3m\": [\n",
      "      2,\n",
      "      7\n",
      "    ],\n",
      "    \"4H\": [\n",
      "      1,\n",
      "      7\n",
      "    ],\n",
      "    \"1H\": [\n",
      "      1,\n",
      "      7\n",
      "    ],\n",
      "    \"15m\": [\n",
      "      1,\n",
      "      7\n",
      "    ],\n",
      "    \"1D\": [\n",
      "      1,\n",
      "      7\n",
      "    ],\n",
      "    \"30m\": [\n",
      "      1,\n",
      "      7\n",
      "    ]\n",
      "  },\n",
      "  \"2KsS85WYuksR6M9wEjGxgiNayoFdHdY4o7g5692Xpump\": {\n",
      "    \"1m\": [\n",
      "      6,\n",
      "      7\n",
      "    ],\n",
      "    \"5m\": [\n",
      "      2,\n",
      "      7\n",
      "    ],\n",
      "    \"3m\": [\n",
      "      2,\n",
      "      7\n",
      "    ],\n",
      "    \"4H\": [\n",
      "      1,\n",
      "      7\n",
      "    ],\n",
      "    \"1H\": [\n",
      "      1,\n",
      "      7\n",
      "    ],\n",
      "    \"15m\": [\n",
      "      1,\n",
      "      7\n",
      "    ],\n",
      "    \"1D\": [\n",
      "      1,\n",
      "      7\n",
      "    ],\n",
      "    \"30m\": [\n",
      "      1,\n",
      "      7\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n",
      "Example of accessing the data:\n",
      "Token: 5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump\n",
      "  Timeframe: 1m\n",
      "  Data shape: (8, 7)\n",
      "  First few rows:\n",
      "                                                          address     close  \\\n",
      "timestamp                                                                     \n",
      "2024-10-21 18:19:00  5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump  0.000072   \n",
      "2024-10-21 18:20:00  5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump  0.000114   \n",
      "2024-10-21 18:21:00  5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump  0.000107   \n",
      "2024-10-21 18:22:00  5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump  0.000048   \n",
      "2024-10-21 18:23:00  5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump  0.000052   \n",
      "\n",
      "                         high       low      open type        volume  \n",
      "timestamp                                                             \n",
      "2024-10-21 18:19:00  0.000134  0.000064  0.000064   1m  2.724036e+08  \n",
      "2024-10-21 18:20:00  0.000136  0.000067  0.000072   1m  6.180043e+08  \n",
      "2024-10-21 18:21:00  0.000178  0.000077  0.000114   1m  6.733344e+08  \n",
      "2024-10-21 18:22:00  0.000107  0.000046  0.000107   1m  5.070212e+08  \n",
      "2024-10-21 18:23:00  0.000052  0.000027  0.000048   1m  4.486848e+08  \n",
      "\n",
      "\n",
      "  Timeframe: 5m\n",
      "  Data shape: (3, 7)\n",
      "  First few rows:\n",
      "                                                          address     close  \\\n",
      "timestamp                                                                     \n",
      "2024-10-21 18:15:00  5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump  0.000072   \n",
      "2024-10-21 18:20:00  5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump  0.000027   \n",
      "2024-10-21 18:25:00  5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump  0.000014   \n",
      "\n",
      "                         high       low      open type        volume  \n",
      "timestamp                                                             \n",
      "2024-10-21 18:15:00  0.000134  0.000064  0.000064   5m  2.724036e+08  \n",
      "2024-10-21 18:20:00  0.000178  0.000025  0.000072   5m  2.638614e+09  \n",
      "2024-10-21 18:25:00  0.000042  0.000014  0.000027   5m  3.242045e+08  \n",
      "\n",
      "\n",
      "  Timeframe: 3m\n",
      "  Data shape: (3, 7)\n",
      "  First few rows:\n",
      "                                                          address     close  \\\n",
      "timestamp                                                                     \n",
      "2024-10-21 18:18:00  5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump  0.000114   \n",
      "2024-10-21 18:21:00  5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump  0.000052   \n",
      "2024-10-21 18:24:00  5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump  0.000014   \n",
      "\n",
      "                         high       low      open type        volume  \n",
      "timestamp                                                             \n",
      "2024-10-21 18:18:00  0.000136  0.000064  0.000064   3m  8.904078e+08  \n",
      "2024-10-21 18:21:00  0.000178  0.000027  0.000114   3m  1.629040e+09  \n",
      "2024-10-21 18:24:00  0.000055  0.000014  0.000052   3m  7.157734e+08  \n",
      "\n",
      "\n",
      "  Timeframe: 4H\n",
      "  Data shape: (1, 7)\n",
      "  First few rows:\n",
      "                                                          address     close  \\\n",
      "timestamp                                                                     \n",
      "2024-10-21 16:00:00  5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump  0.000014   \n",
      "\n",
      "                         high       low      open type        volume  \n",
      "timestamp                                                             \n",
      "2024-10-21 16:00:00  0.000178  0.000014  0.000064   4H  3.247865e+09  \n",
      "\n",
      "\n",
      "  Timeframe: 1H\n",
      "  Data shape: (1, 7)\n",
      "  First few rows:\n",
      "                                                          address     close  \\\n",
      "timestamp                                                                     \n",
      "2024-10-21 18:00:00  5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump  0.000014   \n",
      "\n",
      "                         high       low      open type        volume  \n",
      "timestamp                                                             \n",
      "2024-10-21 18:00:00  0.000178  0.000014  0.000064   1H  3.235222e+09  \n",
      "\n",
      "\n",
      "  Timeframe: 15m\n",
      "  Data shape: (1, 7)\n",
      "  First few rows:\n",
      "                                                          address     close  \\\n",
      "timestamp                                                                     \n",
      "2024-10-21 18:15:00  5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump  0.000014   \n",
      "\n",
      "                         high       low      open type        volume  \n",
      "timestamp                                                             \n",
      "2024-10-21 18:15:00  0.000178  0.000014  0.000064  15m  3.235222e+09  \n",
      "\n",
      "\n",
      "  Timeframe: 1D\n",
      "  Data shape: (1, 7)\n",
      "  First few rows:\n",
      "                                                 address     close      high  \\\n",
      "timestamp                                                                      \n",
      "2024-10-21  5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump  0.000014  0.000178   \n",
      "\n",
      "                 low      open type        volume  \n",
      "timestamp                                          \n",
      "2024-10-21  0.000014  0.000064   1D  3.247865e+09  \n",
      "\n",
      "\n",
      "  Timeframe: 30m\n",
      "  Data shape: (1, 7)\n",
      "  First few rows:\n",
      "                                                          address     close  \\\n",
      "timestamp                                                                     \n",
      "2024-10-21 18:00:00  5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump  0.000014   \n",
      "\n",
      "                         high       low      open type        volume  \n",
      "timestamp                                                             \n",
      "2024-10-21 18:00:00  0.000178  0.000014  0.000064  30m  3.235222e+09  \n",
      "\n",
      "\n",
      "\n",
      "Calculated metrics:\n",
      "Token: 5WtKZBLasEBHz7eZ2PrffQsSreEKUB8dFg7tRn49pump\n",
      "  Timeframe: 1m\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: -80.65%\n",
      "    Volatility: 47.35%\n",
      "  Timeframe: 5m\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: -80.65%\n",
      "    Volatility: 9.21%\n",
      "  Timeframe: 3m\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: -87.80%\n",
      "    Volatility: 13.67%\n",
      "  Timeframe: 4H\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "  Timeframe: 1H\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "  Timeframe: 15m\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "  Timeframe: 1D\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "  Timeframe: 30m\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "\n",
      "\n",
      "Token: 3bxVJsSkWHRZ4UeAg7N5YYxz8Z5AhpnrQj9Fe3wgpump\n",
      "  Timeframe: 1m\n",
      "    Last Price: 0.0001\n",
      "    Daily Return: -48.57%\n",
      "    Volatility: 27.87%\n",
      "  Timeframe: 5m\n",
      "    Last Price: 0.0001\n",
      "    Daily Return: -2.76%\n",
      "    Volatility: 23.69%\n",
      "  Timeframe: 3m\n",
      "    Last Price: 0.0001\n",
      "    Daily Return: 84.65%\n",
      "    Volatility: 34.44%\n",
      "  Timeframe: 4H\n",
      "    Last Price: 0.0001\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "  Timeframe: 1H\n",
      "    Last Price: 0.0001\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "  Timeframe: 15m\n",
      "    Last Price: 0.0001\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "  Timeframe: 1D\n",
      "    Last Price: 0.0001\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "  Timeframe: 30m\n",
      "    Last Price: 0.0001\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "\n",
      "\n",
      "Token: 788rZojRjiwvhTBqgzQvZHZKR84Cv5zzefVLr7kPpump\n",
      "  Timeframe: 1m\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: -0.10%\n",
      "    Volatility: 33.53%\n",
      "  Timeframe: 5m\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: -5.64%\n",
      "    Volatility: nan%\n",
      "  Timeframe: 3m\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: 4.53%\n",
      "    Volatility: nan%\n",
      "  Timeframe: 4H\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "  Timeframe: 1H\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "  Timeframe: 15m\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "  Timeframe: 1D\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "  Timeframe: 30m\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "\n",
      "\n",
      "Token: 2KsS85WYuksR6M9wEjGxgiNayoFdHdY4o7g5692Xpump\n",
      "  Timeframe: 1m\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: -79.10%\n",
      "    Volatility: 67.21%\n",
      "  Timeframe: 5m\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: -58.81%\n",
      "    Volatility: nan%\n",
      "  Timeframe: 3m\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: -39.44%\n",
      "    Volatility: nan%\n",
      "  Timeframe: 4H\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "  Timeframe: 1H\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "  Timeframe: 15m\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "  Timeframe: 1D\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "  Timeframe: 30m\n",
      "    Last Price: 0.0000\n",
      "    Daily Return: 0.00%\n",
      "    Volatility: 0.00%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the most recent folder\n",
    "base_path = 'Data/New_Token_Data'\n",
    "current_date = datetime.now().strftime('%Y_%m_%d')\n",
    "date_folder = os.path.join(base_path, current_date)\n",
    "ohlcv_folder = os.path.join(date_folder, 'OHLCV_Data')\n",
    "ohlcv_datetime_folder = Master_Functions.get_most_recent_folder(ohlcv_folder)\n",
    "\n",
    "# Print the name of the folder being used for import\n",
    "print(f\"Importing OHLCV data from folder: {ohlcv_datetime_folder}\")\n",
    "\n",
    "# Import the OHLCV data\n",
    "imported_ohlcv_data = Master_Functions.import_ohlcv_data(ohlcv_datetime_folder)\n",
    "\n",
    "# Print the structure of the imported OHLCV data dictionary\n",
    "print(\"\\nStructure of imported OHLCV data:\")\n",
    "ohlcv_structure = {token: {timeframe: df.shape for timeframe, df in timeframes.items()} for token, timeframes in imported_ohlcv_data.items()}\n",
    "print(json.dumps(ohlcv_structure, indent=2))\n",
    "\n",
    "# Example of how to access the data\n",
    "print(\"\\nExample of accessing the data:\")\n",
    "for token_address, timeframes in imported_ohlcv_data.items():\n",
    "    print(f\"Token: {token_address}\")\n",
    "    for timeframe, df in timeframes.items():\n",
    "        print(f\"  Timeframe: {timeframe}\")\n",
    "        print(f\"  Data shape: {df.shape}\")\n",
    "        print(f\"  First few rows:\")\n",
    "        print(df.head())\n",
    "        print(\"\\n\")\n",
    "    break  # Only print the first token as an example\n",
    "\n",
    "# Example of calculating simple metrics\n",
    "def calculate_metrics(df):\n",
    "    if df.empty:\n",
    "        return {\n",
    "            'last_price': None,\n",
    "            'daily_return': None,\n",
    "            'volatility': None\n",
    "        }\n",
    "    return {\n",
    "        'last_price': df['close'].iloc[-1],\n",
    "        'daily_return': (df['close'].iloc[-1] / df['close'].iloc[0] - 1) * 100 if len(df) > 1 else 0,\n",
    "        'volatility': df['close'].pct_change().std() * 100 if len(df) > 1 else 0\n",
    "    }\n",
    "\n",
    "# Calculate metrics for each token and timeframe\n",
    "metrics = {}\n",
    "for token_address, timeframes in imported_ohlcv_data.items():\n",
    "    metrics[token_address] = {}\n",
    "    for timeframe, df in timeframes.items():\n",
    "        metrics[token_address][timeframe] = calculate_metrics(df)\n",
    "\n",
    "# Display metrics\n",
    "print(\"\\nCalculated metrics:\")\n",
    "for token_address, timeframes in metrics.items():\n",
    "    print(f\"Token: {token_address}\")\n",
    "    for timeframe, metric in timeframes.items():\n",
    "        print(f\"  Timeframe: {timeframe}\")\n",
    "        if metric['last_price'] is not None:\n",
    "            print(f\"    Last Price: {metric['last_price']:.4f}\")\n",
    "            print(f\"    Daily Return: {metric['daily_return']:.2f}%\")\n",
    "            print(f\"    Volatility: {metric['volatility']:.2f}%\")\n",
    "        else:\n",
    "            print(\"    No data available\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
